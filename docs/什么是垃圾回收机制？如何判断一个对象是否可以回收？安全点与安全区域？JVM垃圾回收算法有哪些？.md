# 什么是垃圾回收机制？如何判断一个对象是否可以回收？安全点与安全区域？JVM垃圾回收算法有哪些？
## 什么是垃圾回收机制
Java中对象是采用new或者反射的方法创建的，这些对象的创建都是在堆(Heap)中分配的，所有对象的回收都是由Java虚拟机通过垃圾回收机制完成的。GC为了能够正确释放对象，会监控每个对象的运行状况，对他们的申请、引用、被引用、赋值等状况进行监控。

Java程序员不用担心内存管理，因为垃圾收集器会自动进行管理。但也可以调用System#gc()或Runtime#getRuntime()#gc()进行显示回收，但JVM也可以屏蔽掉显示的垃圾回收调用。

但是不建议在程序中显式的声明 System.gc()，因为显式声明是做堆内存全扫描，也就是 Full GC，这需要停止所有的活动的(Stop The World Collection)，对应用很大可能存在影响。另外调用System.gc()方法后，不会立即执行Full GC，而是虚拟机自己决定的。

## 如何判断一个对象是否可以回收？
### 引用计数法
判断对象是否存活，其中的一种方法是给对象添加一个引用计数器，每当有一个地方引用它，计数器的值就加1，当引用失效时，计数器的值减1，任一时刻，如果对象的计数器值为0，那么这个对象就不会再被使用，这种方法被称为引用计数法。

﻿在整个回收过程中，引用计数器的值会以极快的速度更新，因而计数值的更新任务变得繁重，而且需要给计数器预留足够大的内存空间，以确保它不会溢出。引用计数法的算法很简单，但在实际运用中要考虑非常多的因素，所以它的实现往往比较复杂，更为重要的是它不能解决对象之间的循环引用问题。
```
public class GcDemo {
    public static void main(String[] args) {
        // 在栈中分配内存空间给obj1，然后在堆中创建GcObject对象A
        // 将obj1指向A实例，这时A的引用计数值 = 1
        GcObject obj1 = new GcObject();
        // 同理，GcObject实例B的引用计数值 = 1
        GcObject obj2 = new GcObject();
        // GcObject实例2被引用，所以B引用计数值 = 2
        obj1.instance = obj2;
        // 同理A的引用计数值 = 2
        obj2.instance = obj1;
        // 栈中的obj1不再指向堆中A，这时A的计数值减1，变成1
        obj1 = null;
        // 栈中的obj2不再指向堆中B，这时B的计数值减1，变成1
        obj2 = null;
    }
}
class GcObject {
    public Object instance = null;
}
```
如上代码，若JVM垃圾收集器采用引用计数法，当obj1和obj2不再指向堆中的实例A、B时，虽然A、B已经不可能再被访问，但彼此间相互引用导致计数器的值不为0，最终导致无法回收A和B。

![](/images/引用计数-循环引用.jpeg)

### 可达性分析
由于引用计数法无法释放有循环引用的垃圾。因此主流的Java虚拟机都没有选用引用计数法来管理内存，而是通过可达性分析 (Reachability Analysis)来判定对象是否存活。

﻿可达性分析的基本思路是找到一系列被称为”GC Roots“的对象引用 (Reference) 作为起始节点，通过引用关系向下搜索，能被遍历到的 (可到达的) 对象就被判定为存活，其余对象 (也就是没有被遍历到的) 自然被判定为死亡。这里需要着重理解的是：可达性分析本质是找出活的对象来把其余空间判定为“无用”，而不是找出所有死掉的对象并回收它们占用的空间，简略的示意图如下所示。

![](/images/可达性分析.jpeg)

经过可达性分析后，没有在GC Roots的引用链条上（还包含一些相互引用的对象）的对象将被垃圾回收器回收。但是首次被标记的对象并一定会被回收，它还有自救的机会。一个对象真正的死亡至少需要经历两次标记过程：

    （1）标记所有不可达对象并进行筛选，筛选的标准是该对象重写了finalize()方法且finalize()方法没有被虚拟机调用过，选出的对象将被放置在一个“即将被回收”的队列中。
        若不可达的对象没有重写finalize()方法或者finalize()方法已经被虚拟机调用过了，则不进行刷选，直接等待垃圾回收器进行回收。
        稍后虚拟机会创建一个低优先级的Finalizer线程去遍历队列中的所有对象并执行finalize()方法。
    （2）对队列中的对象进行第二次标记，如果对象在finalize()方法中重新与引用链上的任何一个对象建立关联，那么这个对象将被移除队列，而还留在队列中的对象，就会被回收了。

﻿要正确的实现可达性分析算法，就必须完整地枚举出所有的GC Roots，否则就有可能会漏掉本应存活的对象。GC Roots作为垃圾回收的起点，必须是一系列活的引用 (Reference) 集合，那这个集合中究竟包含哪些引用？总结起来，可作为GC Roots的引用大致包含：

    （1）虚拟机栈中的引用对象(正在被调用方法的引用类型参数、局部变量等)
    （2）类的引用静态变量，这里指的是引用类型，像int等基本数据类型的静态变量肯定不能作为GC Roots。
    （3）在方法区中常量引用的对象，譬如字符串常量池 ( String Table ) 里的引用。
    （4）当前所有已被加载的Java类和类加载器。
    （5）所有被同步锁 ( synchronized关键字 ) 持有的对象引用。
    （6）本地方法栈中JNI 句柄，包括JNI Local Handles和JNI Global Handles。

#### 如何查找GC Roots
当前，所有的垃圾收集器在查找GC Roots时都必须暂停用户线程，这是因为整个枚举的分析过程必须在一个能保证一致性的快照中进行。即不会出现GC Roots的对象引用关系还在不断变化的情况，否则，分析结果的准确性也就无法保证。

**（1）如何枚举出所有的GC Roots呢？**

一种简单的思路就是从一些已知位置(比如JVM栈)开始扫描内存，但是这种方式存在较大的性能损耗，且还可能存在意外持有垃圾对象和对象移动的问题(例如在垃圾回收过程中对内存进行整理，那么就必须更新持有这些对象的引用，将其指向新的位置)。

如今单个Java应用管理的堆内存至少都是GB起步，在GC时若去扫描所有的JVM栈、方法区、寄存器等空间，那么耗时就太长了。Hotspot解决办法也很直接，用空间换时间，即使用额外的数据结构从外部记录下栈和寄存器中哪些位置是引用，这个数据结构被称为OopMap。

栈帧(Stack Frame)中局部变量表用于存放方法参数和局部变量。它的容量是以变量槽为最小单位。这部分信息在编译后就已经存储在字节码中，是 JVM 可以直接使用的。因此HotSpot在类的加载过程中，就可以利用这些信息把对象内什么偏移量是什么类型的数据计算出来，存放到 OopMap中。

除此之外，在即时编译过程中，也会在特定的位置记录下栈里和寄存器里哪些位置是引用。这是因为经过JIT( just in time，即时编译器)编译后的代码，其引用的位置可能会发生变化，比如原来需要从主存中读取数据，经过JIT优化后可以直接从寄存器中读取数据，这时候就需要把这样的变化同步到OopMap中去。

总结起来，HotSpot利用OopMap快速准确地完成GC Roots枚举，从而避免扫描整个栈空间和寄存器。

**（2）如何得到一致性快照呢？**

HotSpot采用JIT compile技术来提高性能，大量的指令会导致引用关系发生变化，如果为每条指令都生成对应的OopMap，就需要很大的额外空间来存储。

﻿因此HotSpot并没有采用这种方式，而是在特定的位置来记录OopMap，这些位置即被称为安全点(Safepoint)。有了安全点的设定，也就决定了用户程序执行时并非在代码指令流的任意位置都能够停顿下来开始垃圾收集，而是强制要求必须执行到达安全点后才能够暂停。达到安全点后，就可以得到一份一致性的快照。诸如，循环末尾、方法临返回前、可能抛出异常的位置都是常见的安全点。

﻿关于安全点，另外一个需要考虑的问题就是，如何在垃圾收集发生时让所有线程 (不包含执行JNI调用线程) 都跑到安全点，然后停顿下来。其有两种实现方式：

    （1）抢断式中断：GC发生时，先中断所有线程，若线程未达安全点，则恢复线程让其继续执行直到达到安全点。
    （2）主动式中断：GC需要中断线程时，设定全局中断标志位，各个线程执行过程时会不停地主动去轮询这个标志，一旦发现中断标志为真时就自己在最近的安全点上主动中断挂起。

﻿Hotspot采用第二种方式。但这有个前提是线程一直在运行，如果用户线程处于Sleep或者Blocked状态，它是没有办法响应虚拟机的中断请求的，很长一段时间都不会走到安全点。这种情况下，虚拟机也不能说一直等到线程重新被激活后再进行垃圾回收，就引入了安全区域(Safe Region) 来解决这个问题。

﻿安全区域：对象的引用关系不会发生变化，如处于Sleep或者Blocked状态的线程。在这个区域中任意地方开始垃圾回收都是安全的。

﻿当线程执行到安全区域代码时，会标识自己已进入安全区，JVM在垃圾收集时就无须关注这些线程。当线程离开安全区域时，它要检查JVM是否已经完成GC Roots的枚举，如果没有完成，它需要一直等待，直到收到可以离开安全区域的信号为止。

![](/images/安全点与OopMap.png)

## ﻿JVM垃圾回收算法
### 复制算法
在复制算法中，回收器将堆空间划分为两个大小相等的半区(semispace)，分别是来源空间(fromspace) 和目标空间(tospace)。在进行垃圾回收时，回收器将存活对象从来源空间复制到目标空间，复制结束后，所有存活对象紧密排布在目标空间一端，最后将来源空间和目标空间互换。半区复制算法的概要如下图所示。

![](/images/GC-复制算法.png)

![](/images/GC-复制算法2.png)

复制算法主要有如下优势：

    （1）吞吐量高：整个GC算法只搜索并复制存活对象，尤其是堆越大，差距越明显，毕竟它消耗的时间只是与活动对象数量成正比。
    （2）可实现高速分配：由于GC完成后空闲空间是一个连续的内存块，在内存分配时，只要申请空间小于空闲内存块，只需要移动free指针即可。
        相较于标记-清理算法使用空闲链表的分配方式，复制算法明显快得多，毕竟要在空闲链表中找到合适大小的内存怎么都得遍历这个链表。
    （3）无碎片
    （4）与缓存兼容：由于所有存活对象都紧密的排布在内存里，非常有利于CPU的高速缓存。

﻿相较于前面的两种GC算法，其劣势主要有：

    （1）堆空间利用率低：复制算法把堆一分为二，只有一半能被使用，内存利用率极低，这也是复制算法的最大缺陷。
    （2）递归调用函数：复制某个对象时要递归复制它引用的对象，相较于迭代算法，递归的效率更低，而且有栈空间溢出的风险。

### 标记清理算法
使用标记-清理算法的回收器在回收过程中分为两个阶段：

    （1）追踪(Trace)阶段：回收器从GC Roots(寄存器、栈、全局变量)开始遍历对象图，并标记所遇到的每个对象；
    （2）清理(Sweep)阶段：回收器检查堆中的每一个对象，并将所有未被标记的对象当作垃圾进行回收。
    
标记清理算法是一种间接回收算法，它并非直接检测垃圾本身，而是先确定所有存活对象，然后反过来判断其他对象都是垃圾。在开始具体的算法内容之前，先明确几个基本概念：

    （1）Mutator：应用的执行者，可以简单的理解为“应用程序”，GC就是在Mutator的内部工作。Mutator主要进行两种操作：创建对象和更新对象间的引用关系。
    （2）Collector：垃圾回收器，有时候也被直接称为回收器；
    （3）Allocator：分配器，当Mutator需要创建新对象时，就会向Allocator申请一个大小合适的空间，Allocator就会在堆中的可用空间中寻找满足要求的空间，返回给Mutator。

简单描述这三者是如何协同工作的：当Mutator需要创建对象时，就会向Allocator申请空间，如果没有足够的内存空间，则唤起Collector，等待Collector完成相关工作后，再次尝试分配内存，如果仍没有足够内存，则说明堆内存耗尽。若使用标记清理算法的垃圾回收器，其垃圾回收过程可用如下代码来描述：
```
// 回收器执行垃圾回收
Collect() {
    // 从 GC Roots 开始标记
    markFromGCRoots();
    // 清理
    sweep(heapStart, heapEnd);
}
```
标记阶段的流程可以大致用如下代码描述：
```
markFromGCRoots() {
    // 初始化一个空的工作列表
    workList = initWorkList();  
    // 遍历所有GC Roots
    for (root in Roots) {
        // 如果根节点未被标记，标记后把它扔到工作列表workList
        if (root != null && !isMarked(root)) {
            setMarked(root);
            workList.push(root);
            // 以此根节点为起点，遍历对象图
            // 如果遇到未被标记的节点就进行标记
            mark();
        }
    }
}
initWorkList() {
    return new Stack();
}
mark() {
    while (isNotEmpty(workList)) {
        // workList里面都是已经标记过的节点
        ref = workList.pop();
        // 获取ref引用的所有节点
        for (child in ref.getAllRefNodes()) {
            if (child != null && !isMarked(child)) {
                setMarked(child);
                workList.add(child);
            }
        }
    }
}
```
清冽阶段的流程可以大致用如下代码描述：
```
sweep(heapStart, heapEnd) {
  object = heapStart;
    // 线性扫描所有堆空间
    // 如果对象已被标记则释放其标记位
    // 如果对象未被标记则释放其内存空间
    while (object < heapEnd) {
      if (isMarked(object)) {
          unsetMarked(object);
        } else {
          free(object);
        }
        object = object.next();
    }
}
```
标记清理算法的优点是算法简单，实现容易。而缺点也很明显：

    （1）内存碎片化：堆内存中容易出现大量碎片，不仅会导致内存利用率低，还会严重影响内存的分配速度，毕竟碎片越多，找到合适大小内存就越慢；
    （2）GC效率低：由于Collector在清除阶段会遍历所有堆进行垃圾回收，堆越大，清除阶段花费的时间就会越长，因此GC时间与堆空间大小成正比；
    （3）STW：标记清理算法的基本假设是对象间的引用关系不会在标记阶段发生变化，也就是说执行标记操作时，需要暂停所有可能修改对象引用关系的线程。

### ﻿标记整理算法

![](/images/GC-标记整理算法.png)

标记-整理算法的执行还是分为两个部分，首先是标记阶段，这个阶段与标记清理算法该阶段一致；然后是整理阶段，移动存活对象位置，同时更新所有指向被移动对象的指针。这类算法通常需要多次遍历堆空间，比如第一次遍历算出存活对象应当移动到哪个位置，接下来的遍历才会去移动对象。而不同的算法，堆的遍历次数、整理过程所遵循的顺序，对象的移动方式都有所不同，所以这些算法间的性能差异非常明显。通常情况下，整理算法重排堆中对象时采用下述三种策略：

    （1）任意顺序(Arbitrary)：对象的移动方式与它们的原始排序顺序和引用关系无关，可以把对象移动到任意位置。
        其实现简单且执行快速，但这种整理方式可能会把原来相邻的对象分散到不同的高速缓存行或虚拟内存页，从而降低空间的局部性(locality)。
    （2）线性(Linearising)：将具有关联关系的对象排列在一起，比如具有引用关系的对象，或同一数据结构中的相邻对象。
        其最关键的问题是，很难评估将具有什么样关联关系的对象排在一起有更好的性能。所以几乎看不到使用这种策略实现的整理算法。
    （3）滑动(Sliding)：将存活对象滑动到堆的一端，挤出垃圾，保证原有顺序。由于它不改变对象的相对排列熟悉，不会影响赋值器的局部性，所以现代的标记-整理回收器均使用这一策略。

前文多次提到局部性，局部性原理指的是，对于应用程序来说，总是趋向于访问最近已经使用过的指令和数据，或者附近的指令和数据。从时间维度来看，刚刚访问的指令和数据，在不远的未来很有可能被再次访问；从空间维度来看，刚刚被访问的指令和数据，其附近的指令和数据在不远的未来很有可能被再次访问。

局部性原理在计算机领域应用非常广泛，比如计算机存储器的分级：离CPU越近的存储器，速度越快，因此寄存器的访问速度最快，其次是各种高速缓存，然后才是内存、磁盘等。CPU正在访问的指令或数据往往会再次访问，所以在第一次访问后，会将其复制到高速缓存中，下次访问时就无需再次从内存中读取。再例如MySQL InnoDB从磁盘读取数据时，并非按需读取，而是按页读取，一次至少读取一页数据，如果未来要读取的数据就在页中，就能够省去后续的磁盘I/O。

﻿整理算法的最大优势是可以有效减少内存碎片，但它也有不少限制：

    （1）采用任意策略的整理算法只能处理单一大小对象，或只能对不同大小的对象分别进行整（双指针算法）；
    （2）整理过程需要两次甚至三次整堆遍历；
    （3）对象头部可能需要一个额外的槽来保存迁移信息，这对通用内存管理器来说是一个显著的额外开销。

而为了最大限度地避免这些限制，前人发明了不同的整理算法，例如双指针整理算法、Lisp 2 算法。